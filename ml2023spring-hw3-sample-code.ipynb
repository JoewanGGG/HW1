{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"## HW3 Image Classification\n#### Solve image classification with convolutional neural networks(CNN).\n#### If you have any questions, please contact the TAs via TA hours, NTU COOL, or email to mlta-2023-spring@googlegroups.com","metadata":{"execution":{"iopub.status.busy":"2023-08-09T07:49:28.602320Z","iopub.execute_input":"2023-08-09T07:49:28.602977Z","iopub.status.idle":"2023-08-09T07:49:28.608396Z","shell.execute_reply.started":"2023-08-09T07:49:28.602927Z","shell.execute_reply":"2023-08-09T07:49:28.607184Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# check GPU type.\n!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2023-08-09T07:49:28.610496Z","iopub.execute_input":"2023-08-09T07:49:28.611581Z","iopub.status.idle":"2023-08-09T07:49:29.721550Z","shell.execute_reply.started":"2023-08-09T07:49:28.611536Z","shell.execute_reply":"2023-08-09T07:49:29.720263Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Wed Aug  9 07:49:29 2023       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   48C    P0    28W /  70W |    584MiB / 15109MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n|   1  Tesla T4            Off  | 00000000:00:05.0 Off |                    0 |\n| N/A   37C    P8     9W /  70W |      3MiB / 15109MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n+-----------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Import Packages","metadata":{}},{"cell_type":"code","source":"_exp_name = \"sample\"","metadata":{"execution":{"iopub.status.busy":"2023-08-09T07:49:29.723795Z","iopub.execute_input":"2023-08-09T07:49:29.724215Z","iopub.status.idle":"2023-08-09T07:49:29.729766Z","shell.execute_reply.started":"2023-08-09T07:49:29.724165Z","shell.execute_reply":"2023-08-09T07:49:29.728570Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Import necessary packages.\nimport numpy as np\nimport pandas as pd\nimport torch\nimport os\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nfrom PIL import Image\n# \"ConcatDataset\" and \"Subset\" are possibly useful when doing semi-supervised learning.\nfrom torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset\nfrom torchvision.datasets import DatasetFolder, VisionDataset\n# This is for the progress bar.\nfrom tqdm.auto import tqdm\nimport random","metadata":{"execution":{"iopub.status.busy":"2023-08-09T07:49:29.734017Z","iopub.execute_input":"2023-08-09T07:49:29.734502Z","iopub.status.idle":"2023-08-09T07:49:29.743945Z","shell.execute_reply.started":"2023-08-09T07:49:29.734458Z","shell.execute_reply":"2023-08-09T07:49:29.742792Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"myseed = 6666  # set a random seed for reproducibility\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\nnp.random.seed(myseed)\ntorch.manual_seed(myseed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(myseed)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T07:49:29.746412Z","iopub.execute_input":"2023-08-09T07:49:29.746769Z","iopub.status.idle":"2023-08-09T07:49:29.755252Z","shell.execute_reply.started":"2023-08-09T07:49:29.746727Z","shell.execute_reply":"2023-08-09T07:49:29.754042Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### Transforms","metadata":{}},{"cell_type":"code","source":"# Normally, We don't need augmentations in testing and validation.\n# All we need here is to resize the PIL image and transform it into Tensor.\ntest_tfm = transforms.Compose([\n    transforms.Resize((128, 128)),\n    transforms.ToTensor(),\n])\n\n# However, it is also possible to use augmentation in the testing phase.\n# You may use train_tfm to produce a variety of images and then test using ensemble methods\ntrain_tfm = transforms.Compose([\n    transforms.Resize((128, 128)),\n    transforms.RandomHorizontalFlip(p=1),   # 随机水平翻转\n    transforms.RandomVerticalFlip(p=1),     # 随机上下翻转\n    transforms.RandomGrayscale(0.5), # 随机灰度化\n    transforms.RandomSolarize(threshold=192.0),\n    transforms.ColorJitter(brightness=.5,hue=0.5), # 改变图像的亮度和饱和度\n    transforms.RandomRotation(degrees=(0, 180)), # 图像随机旋转\n    transforms.RandomInvert(),# 改变图像的颜色\n    # You may add some transforms here.\n    # ToTensor() should be the last one of the transforms.\n    transforms.ToTensor(),\n    \n])","metadata":{"execution":{"iopub.status.busy":"2023-08-09T07:49:29.757448Z","iopub.execute_input":"2023-08-09T07:49:29.757903Z","iopub.status.idle":"2023-08-09T07:49:29.769905Z","shell.execute_reply.started":"2023-08-09T07:49:29.757848Z","shell.execute_reply":"2023-08-09T07:49:29.768804Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"### Datasets","metadata":{}},{"cell_type":"code","source":"class FoodDataset(Dataset):\n\n    def __init__(self,path,tfm=test_tfm,files = None):\n        super(FoodDataset).__init__()\n        self.path = path\n        self.files = sorted([os.path.join(path,x) for x in os.listdir(path) if x.endswith(\".jpg\")])\n        if files != None:\n            self.files = files\n            \n        self.transform = tfm\n  \n    def __len__(self):\n        return len(self.files)\n  \n    def __getitem__(self,idx):\n        fname = self.files[idx]\n        im = Image.open(fname)\n        im = self.transform(im)\n        \n        try:\n            label = int(fname.split(\"/\")[-1].split(\"_\")[0])\n        except:\n            label = -1 # test has no label\n            \n        return im,label","metadata":{"execution":{"iopub.status.busy":"2023-08-09T07:49:29.771957Z","iopub.execute_input":"2023-08-09T07:49:29.772341Z","iopub.status.idle":"2023-08-09T07:49:29.783532Z","shell.execute_reply.started":"2023-08-09T07:49:29.772305Z","shell.execute_reply":"2023-08-09T07:49:29.782431Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"### Model","metadata":{}},{"cell_type":"code","source":"class Classifier(nn.Module):\n    def __init__(self):\n        super(Classifier, self).__init__()\n        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n        # input 維度 [3, 128, 128]\n        self.cnn = nn.Sequential(\n            nn.Conv2d(3, 64, 3, 1, 1),  # [64, 128, 128]\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2, 0),      # [64, 64, 64]\n\n            nn.Conv2d(64, 128, 3, 1, 1), # [128, 64, 64]\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2, 0),      # [128, 32, 32]\n\n            nn.Conv2d(128, 256, 3, 1, 1), # [256, 32, 32]\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2, 0),      # [256, 16, 16]\n\n            nn.Conv2d(256, 512, 3, 1, 1), # [512, 16, 16]\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2, 0),       # [512, 8, 8]\n            \n            nn.Conv2d(512, 512, 3, 1, 1), # [512, 8, 8]\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2, 0),       # [512, 4, 4]\n        )\n        self.fc = nn.Sequential(\n            nn.Linear(512*4*4, 1024),\n            nn.ReLU(),\n            nn.Linear(1024, 512),\n            nn.ReLU(),\n            nn.Linear(512, 11)\n        )\n\n    def forward(self, x):\n        out = self.cnn(x)\n        out = out.view(out.size()[0], -1)\n        return self.fc(out)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T07:49:29.785052Z","iopub.execute_input":"2023-08-09T07:49:29.786047Z","iopub.status.idle":"2023-08-09T07:49:29.800652Z","shell.execute_reply.started":"2023-08-09T07:49:29.786006Z","shell.execute_reply":"2023-08-09T07:49:29.799470Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"### Configurations","metadata":{}},{"cell_type":"code","source":"# \"cuda\" only when GPUs are available.\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Initialize a model, and put it on the device specified.\nmodel = Classifier().to(device)\n\n# The number of batch size.\nbatch_size = 64\n\n# The number of training epochs.\nn_epochs = 8\n\n# If no improvement in 'patience' epochs, early stop.\npatience = 300\n\n# For the classification task, we use cross-entropy as the measurement of performance.\ncriterion = nn.CrossEntropyLoss()\n\n# Initialize optimizer, you may fine-tune some hyperparameters such as learning rate on your own.\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0003, weight_decay=1e-5)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T07:49:29.802344Z","iopub.execute_input":"2023-08-09T07:49:29.802847Z","iopub.status.idle":"2023-08-09T07:49:29.962600Z","shell.execute_reply.started":"2023-08-09T07:49:29.802805Z","shell.execute_reply":"2023-08-09T07:49:29.961396Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"### Dataloader","metadata":{}},{"cell_type":"code","source":"# Construct train and valid datasets.\n# The argument \"loader\" tells how torchvision reads the data.\ntrain_set = FoodDataset(\"/kaggle/input/ml2023spring-hw3/train\", tfm=train_tfm)\ntrain_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\nvalid_set = FoodDataset(\"/kaggle/input/ml2023spring-hw3/valid\", tfm=test_tfm)\nvalid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T07:49:29.966498Z","iopub.execute_input":"2023-08-09T07:49:29.966814Z","iopub.status.idle":"2023-08-09T07:49:30.021055Z","shell.execute_reply.started":"2023-08-09T07:49:29.966782Z","shell.execute_reply":"2023-08-09T07:49:30.019811Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"### Start Training","metadata":{}},{"cell_type":"code","source":"# Initialize trackers, these are not parameters and should not be changed\nstale = 0\nbest_acc = 0\n\nfor epoch in range(n_epochs):\n\n    # ---------- Training ----------\n    # Make sure the model is in train mode before training.\n    model.train()\n\n    # These are used to record information in training.\n    train_loss = []\n    train_accs = []\n\n    for batch in tqdm(train_loader):\n\n        # A batch consists of image data and corresponding labels.\n        imgs, labels = batch\n        #imgs = imgs.half()\n        #print(imgs.shape,labels.shape)\n\n        # Forward the data. (Make sure data and model are on the same device.)\n        logits = model(imgs.to(device))\n\n        # Calculate the cross-entropy loss.\n        # We don't need to apply softmax before computing cross-entropy as it is done automatically.\n        loss = criterion(logits, labels.to(device))\n\n        # Gradients stored in the parameters in the previous step should be cleared out first.\n        optimizer.zero_grad()\n\n        # Compute the gradients for parameters.\n        loss.backward()\n\n        # Clip the gradient norms for stable training.\n        grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n\n        # Update the parameters with computed gradients.\n        optimizer.step()\n\n        # Compute the accuracy for current batch.\n        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n\n        # Record the loss and accuracy.\n        train_loss.append(loss.item())\n        train_accs.append(acc)\n        \n    train_loss = sum(train_loss) / len(train_loss)\n    train_acc = sum(train_accs) / len(train_accs)\n\n    # Print the information.\n    print(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n\n    # ---------- Validation ----------\n    # Make sure the model is in eval mode so that some modules like dropout are disabled and work normally.\n    model.eval()\n\n    # These are used to record information in validation.\n    valid_loss = []\n    valid_accs = []\n\n    # Iterate the validation set by batches.\n    for batch in tqdm(valid_loader):\n\n        # A batch consists of image data and corresponding labels.\n        imgs, labels = batch\n        #imgs = imgs.half()\n\n        # We don't need gradient in validation.\n        # Using torch.no_grad() accelerates the forward process.\n        with torch.no_grad():\n            logits = model(imgs.to(device))\n\n        # We can still compute the loss (but not the gradient).\n        loss = criterion(logits, labels.to(device))\n\n        # Compute the accuracy for current batch.\n        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n\n        # Record the loss and accuracy.\n        valid_loss.append(loss.item())\n        valid_accs.append(acc)\n        #break\n\n    # The average loss and accuracy for entire validation set is the average of the recorded values.\n    valid_loss = sum(valid_loss) / len(valid_loss)\n    valid_acc = sum(valid_accs) / len(valid_accs)\n\n    # Print the information.\n    print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n\n\n    # update logs\n    if valid_acc > best_acc:\n        with open(f\"./{_exp_name}_log.txt\",\"a\"):\n            print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f} -> best\")\n    else:\n        with open(f\"./{_exp_name}_log.txt\",\"a\"):\n            print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n\n\n    # save models\n    if valid_acc > best_acc:\n        print(f\"Best model found at epoch {epoch}, saving model\")\n        torch.save(model.state_dict(), f\"{_exp_name}_best.ckpt\") # only save best to prevent output memory exceed error\n        best_acc = valid_acc\n        stale = 0\n    else:\n        stale += 1\n        if stale > patience:\n            print(f\"No improvment {patience} consecutive epochs, early stopping\")\n            break","metadata":{"execution":{"iopub.status.busy":"2023-08-09T07:49:30.023043Z","iopub.execute_input":"2023-08-09T07:49:30.023922Z","iopub.status.idle":"2023-08-09T08:17:54.133089Z","shell.execute_reply.started":"2023-08-09T07:49:30.023881Z","shell.execute_reply":"2023-08-09T08:17:54.131205Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c567cb766834225a5157de977a3ecf0"}},"metadata":{}},{"name":"stdout","text":"[ Train | 001/008 ] loss = 2.28860, acc = 0.17645\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/57 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7deeda6f39ea4f538d039420b45344d1"}},"metadata":{}},{"name":"stdout","text":"[ Valid | 001/008 ] loss = 2.23674, acc = 0.20238\n[ Valid | 001/008 ] loss = 2.23674, acc = 0.20238 -> best\nBest model found at epoch 0, saving model\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"426f958aaa2a48d7898576e4117780de"}},"metadata":{}},{"name":"stdout","text":"[ Train | 002/008 ] loss = 2.21079, acc = 0.21875\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/57 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a07b4c4c647949aaa1aa70a527637921"}},"metadata":{}},{"name":"stdout","text":"[ Valid | 002/008 ] loss = 2.14357, acc = 0.25654\n[ Valid | 002/008 ] loss = 2.14357, acc = 0.25654 -> best\nBest model found at epoch 1, saving model\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98a6f5e00c4043ef8d82d82c097585b3"}},"metadata":{}},{"name":"stdout","text":"[ Train | 003/008 ] loss = 2.13395, acc = 0.24403\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/57 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05f6cfcdae204b759f8e7fb35de93246"}},"metadata":{}},{"name":"stdout","text":"[ Valid | 003/008 ] loss = 2.04105, acc = 0.28436\n[ Valid | 003/008 ] loss = 2.04105, acc = 0.28436 -> best\nBest model found at epoch 2, saving model\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91b59d3bd3c54f4d814142aa14bbf7f0"}},"metadata":{}},{"name":"stdout","text":"[ Train | 004/008 ] loss = 2.07540, acc = 0.26861\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/57 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47c2469375164fc490025a146758e912"}},"metadata":{}},{"name":"stdout","text":"[ Valid | 004/008 ] loss = 2.05220, acc = 0.27344\n[ Valid | 004/008 ] loss = 2.05220, acc = 0.27344\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b05a8a9fba46400ca8f0fa5d34a2e880"}},"metadata":{}},{"name":"stdout","text":"[ Train | 005/008 ] loss = 2.00601, acc = 0.29717\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/57 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ce07ff2cd04479e8af9213584bac50a"}},"metadata":{}},{"name":"stdout","text":"[ Valid | 005/008 ] loss = 1.94490, acc = 0.31358\n[ Valid | 005/008 ] loss = 1.94490, acc = 0.31358 -> best\nBest model found at epoch 4, saving model\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c98c45aef4b430689ea1a00fe292a76"}},"metadata":{}},{"name":"stdout","text":"[ Train | 006/008 ] loss = 1.98323, acc = 0.30354\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/57 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"312080c5a7ec4ad6a2255026d7980c12"}},"metadata":{}},{"name":"stdout","text":"[ Valid | 006/008 ] loss = 1.94436, acc = 0.28982\n[ Valid | 006/008 ] loss = 1.94436, acc = 0.28982\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ec9203bec474a85bcb83dc1ee9ece77"}},"metadata":{}},{"name":"stdout","text":"[ Train | 007/008 ] loss = 1.93838, acc = 0.31310\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/57 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9c0ee315a56487c84e25bb36056f7e7"}},"metadata":{}},{"name":"stdout","text":"[ Valid | 007/008 ] loss = 1.88494, acc = 0.33222\n[ Valid | 007/008 ] loss = 1.88494, acc = 0.33222 -> best\nBest model found at epoch 6, saving model\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"226eb472355c48ea87873505c90823a6"}},"metadata":{}},{"name":"stdout","text":"[ Train | 008/008 ] loss = 1.88462, acc = 0.33061\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/57 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"847551884bbc46fbbb36e21842335099"}},"metadata":{}},{"name":"stdout","text":"[ Valid | 008/008 ] loss = 1.90923, acc = 0.31539\n[ Valid | 008/008 ] loss = 1.90923, acc = 0.31539\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Dataloader for test","metadata":{}},{"cell_type":"code","source":"# Construct test datasets.\n# The argument \"loader\" tells how torchvision reads the data.\ntest_set = FoodDataset(\"/kaggle/input/ml2023spring-hw3/test\", tfm=test_tfm)\ntest_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T08:17:54.134877Z","iopub.execute_input":"2023-08-09T08:17:54.135604Z","iopub.status.idle":"2023-08-09T08:17:54.697462Z","shell.execute_reply.started":"2023-08-09T08:17:54.135561Z","shell.execute_reply":"2023-08-09T08:17:54.696328Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"### Testing and generate prediction CSV","metadata":{}},{"cell_type":"code","source":"model_best = Classifier().to(device)\nmodel_best.load_state_dict(torch.load(f\"{_exp_name}_best.ckpt\"))\nmodel_best.eval()\nprediction = []\nwith torch.no_grad():\n    for data,_ in tqdm(test_loader):\n        test_pred = model_best(data.to(device))\n        test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n        prediction += test_label.squeeze().tolist()","metadata":{"execution":{"iopub.status.busy":"2023-08-09T08:17:54.699391Z","iopub.execute_input":"2023-08-09T08:17:54.699788Z","iopub.status.idle":"2023-08-09T08:19:03.120386Z","shell.execute_reply.started":"2023-08-09T08:17:54.699745Z","shell.execute_reply":"2023-08-09T08:19:03.119402Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/47 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47f8a4603cc74df2a2f7c950d370c4b0"}},"metadata":{}}]},{"cell_type":"code","source":"#create test csv\ndef pad4(i):\n    return \"0\"*(4-len(str(i)))+str(i)\ndf = pd.DataFrame()\ndf[\"Id\"] = [pad4(i) for i in range(len(test_set))]\ndf[\"Category\"] = prediction\ndf.to_csv(\"submission.csv\",index = False)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T08:19:03.123865Z","iopub.execute_input":"2023-08-09T08:19:03.127320Z","iopub.status.idle":"2023-08-09T08:19:03.170868Z","shell.execute_reply.started":"2023-08-09T08:19:03.127275Z","shell.execute_reply":"2023-08-09T08:19:03.169757Z"},"trusted":true},"execution_count":26,"outputs":[]}]}